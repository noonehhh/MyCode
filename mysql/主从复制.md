### 主从复制

--------

~~~
mysql数据库提供了一种主从备份的机制，其实就是把主数据库的所有的数据同时写到备份的数据库中。实现mysql数据库的热备份。
~~~

##### 要求

~~~
主从数据库最好版本一致，要实现热备mysql的版本都高于3.2。还有一个基本的原则就是作为从数据库的数据版本可以高于主服务器数据库的版本，
但是不可以低于主服务器的数据库版本。
~~~

##### 配置

**主库配置**

**修改Master上MySQL配置文件my.cnf**

~~~
[mysqld]
log-bin=mysql-bin   // [必须]启用二进制日志
server-id=1         // [必须]服务器唯一ID
binlog-do-db = db1  // #需要复制的数据库名，如果复制多个数据库，重复设置这个选项即可                   
~~~

**检查MySQL是否允许远程连接**

~~~
 bind-address = 0.0.0.0       #这样表示允许所有网段连接
~~~

**重启MySQL，创建允许从服务器同步数据的账户**

~~~
mysql> GRANT REPLICATION backup ON *.* to 'backup'@'192.168.128.%' identified by 'backup';
mysql> FLUSH PRIVILEGES;
~~~

**从库配置**

**修改Slave上MySQL配置文件my.cnf**

~~~
[mysqld]
server_id = 2
log-bin = mysql-bin
log-slave-updates
sync_binlog = 0
#log buffer将每秒一次地写入log file中，并且log file的flush(刷到磁盘)操作同时进行。该模式下在事务提交的时候，不会主动触发写入磁盘的操作
innodb_flush_log_at_trx_commit = 0        
#指定slave要复制哪个库
replicate-do-db = db         
#MySQL主从复制的时候，当Master和Slave之间的网络中断，但是Master和Slave无法察觉的情况下（比如防火墙或者路由问题）。
Slave会等待slave_net_timeout设置的秒数后，才能认为网络出现故障，然后才会重连并且追赶这段时间主库的数据
slave-net-timeout = 60                    
log_bin_trust_function_creators = 1
~~~

**执行同步命令**

~~~
#执行同步命令，设置主服务器ip，同步账号密码，同步位置
mysql>change master to master_host='10.10.20.111',master_user='account',master_password='123456',master_log_file='mysql-bin.000033',master_log_pos=337523;
#开启同步功能
mysql>start slave;
~~~

**查看Slave状态**

~~~
mysql>show slave status\G;
*************************** 1. row ***************************
               Slave_IO_State: Waiting for master to send event
                  Master_Host: 10.10.20.111
                  Master_User: account
                  Master_Port: 3306
                Connect_Retry: 60
              Master_Log_File: mysql-bin.000033
          Read_Master_Log_Pos: 337523
               Relay_Log_File: db2-relay-bin.000002
                Relay_Log_Pos: 337686
        Relay_Master_Log_File: mysql-bin.000033
             Slave_IO_Running: Yes
            Slave_SQL_Running: Yes
              Replicate_Do_DB:
          Replicate_Ignore_DB:
          ...
~~~

##### 原理

~~~
Master更新写入二进制日志文件，并维护日志文件的索引。Slave从二进制文件读取更新内容，在Slave上重新执行一遍来进行备份。
~~~

`MySQL` 主从复制默认是 **异步的模式**

###### Master

>1、当主节点上进行 `insert、update、delete` 操作时，会按照时间先后顺序写入到 `binlog` 中；
>
>2、当从节点连接到主节点时，主节点会创建一个叫做 `binlog dump` 的线程；
>
>3、一个主节点有多少个从节点，就会创建多少个 `binlog dump` 线程；
>
>4、当主节点的 `binlog` 发生变化的时候，也就是进行了更改操作，`binlog dump` 线程就会通知从节点 (`Push`模式)，并将相应的 `binlog` 内容发送给从节点；

###### Slave

>当开启主从同步的时候，从节点会创建两个线程用来完成数据同步的工作。
>
>**I/O线程：** 此线程连接到主节点，主节点上的 `binlog dump` 线程会将 `binlog` 的内容发送给此线程。此线程接收到 `binlog` 内容后，再将内容写入到本地的 `relay log`。
>
>**SQL线程：** 该线程读取 `I/O` 线程写入的 `relay log`，并且根据 `relay log` 的内容对从数据库做对应的操作。

![](https://github.com/No8LaVine/MyCode/blob/master/images/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B61.jpg)

主从配置一般都是和读写分离相结合，主服务器负责写数据，从服务器负责读数据，并保证主服务器的数据及时同步到从服务器。

**relay log 是怎么产生的呢？**

从服务器 `I/O` 线程将主服务器的 `Binlog` 日志读取过来，解析到各类 `Events` 之后记录到从服务器本地文件，这个文件就被称为 `relay log`。

##### binlog写入机制

`binlog`的写入逻辑比较简单：事务执行过程中，先把日志写到`binlog cache`，事务提交的时候，再把`binlog cache`写到`binlog`文件中。

~~~
一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了binlog cache的保存问题。

系统给binlog cache分配了一片内存，每个线程一个，参数 binlog_cache_size用于控制单个线程内binlog cache所占内存的大小。
如果超过了这个参数规定的大小，就要暂存到磁盘。

事务提交的时候，执行器把binlog cache里的完整事务写入到binlog中，并清空binlog cache。
~~~

![](https://github.com/No8LaVine/MyCode/blob/master/images/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B62.png)

可以看到，每个线程有自己`binlog cache`，但是共用同一份`binlog`文件。

- 图中的`write`，指的就是指把日志写入到文件系统的`page cache`，并没有把数据持久化到磁盘，所以速度比较快。
- 图中的`fsync`，才是将数据持久化到磁盘的操作。一般情况下，我们认为`fsync`才占磁盘的`IOPS`。

`write` 和`fsync`的时机，是由参数`sync_binlog`控制的：

1. `sync_binlog=0`的时候，表示每次提交事务都只`write`，不`fsync`；
2. `sync_binlog=1`的时候，表示每次提交事务都会执行`fsync`；
3. `sync_binlog=N(N>1)`的时候，表示每次提交事务都`write`，但累积`N`个事务后才`fsync`。

因此，在出现`IO`瓶颈的场景里，将`sync_binlog`设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成0，比较常见的是将其设置为100~1000中的某个数值。

但是，将`sync_binlog`设置为N，对应的风险是：如果主机发生异常重启，会丢失最近`N`个事务的`binlog`日志。

##### binlog三种模式对比

~~~
statement：基于SQL语句的模式，某些语句中含有一些函数，例如 UUID NOW 等在复制过程可能导致数据不一致甚至出错。

row：基于行的模式，记录的是行的变化，很安全。但是 binlog 的磁盘占用会比其他两种模式大很多，在一些大表中清除大量数据时
在 binlog 中会生成很多条语句，可能导致从库延迟变大。

mixed：混合模式，根据语句来选用是 statement 还是 row 模式。
~~~

#### MySQL-5.5支持半同步复制

~~~
早期的MySQL复制只能是基于异步来实现，从MySQL-5.5开始，支持半自动复制。在以前的异步（asynchronous）复制中，主库在执行完一
些事务后，是不会管备库的进度的。如果备库处于落后，而更不幸的是主库此时又出现Crash（例如宕机），这时备库中的数据就是不完整的。
简而言之，在主库发生故障的时候，我们无法使用备库来继续提供数据一致的服务了。Semisynchronous Replication(半同步复制)
则一定程度上保证提交的事务已经传给了至少一个备库。Semi synchronous中，仅仅保证事务的已经传递到备库上，但是并不确保已经
在备库上执行完成了。

此外，还有一种情况会导致主备数据不一致。在某个session中，主库上提交一个事务后，会等待事务传递给至少一个备库，如果在这个等待
过程中主库Crash，那么也可能备库和主库不一致，这是很致命的。如果主备网络故障或者备库挂了，主库在事务提交后等待10秒
（rpl_semi_sync_master_timeout的默认值）后，就会继续。这时，主库就会变回原来的异步状态。

MySQL在加载并开启Semi-sync插件后，每一个事务需等待备库接收日志后才返回给客户端。如果做的是小事务，两台主机的延迟又较小，
则Semi-sync可以实现在性能很小损失的情况下的零数据丢失。
~~~



#### redo log、undo log和binlog的区别

##### redo log

~~~
又称重做日志文件，用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来,在实例和
介质失败（media failure）时，redo log文件就能派上用场，如数据库掉电，InnoDB存储引擎会使用redo log恢复
到掉电前的时刻，以此来保证数据的完整性。
~~~

###### 作用

~~~
确保事务的持久性。
　　防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。
~~~

###### 产生时间

~~~
事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。
~~~

###### 内容

~~~
物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。
~~~

###### 释放时间

~~~
当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。
~~~



##### undo log

~~~
又称回滚日志，保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读=
~~~

###### 内容

~~~
逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。
~~~

###### 产生时间

~~~
事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性
~~~

###### 释放时间

~~~
当事务提交之后，undo log并不能立马被删除，
　　而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。
~~~

##### 为什么只用 redo log 或者只用 undo log 不可以？

~~~
1.假设只有 undo-log：那么就必须保证提交前刷脏完成，否则宕机时有些修改就在内存中丢失了，破坏了持久性。
（这样带来了一个问题，那就是前面提到的性能差）

2.假设只有 redo-log：那么就不能随心所欲地在事务提交前刷脏，即无法支持大事务。（假如、某张表有 100 亿的 8 字节
整数数据，就算不考虑其他东西带来的损耗，光 update 整张表至少要消耗 80G 的内存。如前所述，有了 undo-log，就可以随便刷脏。）
~~~



##### binlog

~~~
二进制日志
~~~

###### 作用

~~~
1，用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。
2，用于数据库的基于时间点的还原。
~~~

###### 内容

~~~
逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。
　　但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息，
　　也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。
　　在使用mysqlbinlog解析binlog之后一些都会真相大白。
　　因此可以基于binlog做到类似于oracle的闪回功能，其实都是依赖于binlog中的日志记录。
~~~

###### 产生时

~~~
事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。
　　这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。
　　因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。
　　这是因为binlog是在事务提交的时候一次性写入的造成的，这些可以通过测试验证。
~~~

###### 释放时间

~~~
binlog的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。
~~~

##### redo/undo log 和 binlog

两者区别还是挺多的，大致如下，

~~~
- 层次不同。redo/undo 是 innodb 引擎层维护的，而 binlog 是 mysql server 层维护的，跟采用何种引擎没有关系，
记录的是所有引擎的更新操作的日志记录。

- 记录内容不同。redo/undo 记录的是 每个页/每个数据 的修改情况，
属于物理日志+逻辑日志结合的方式
（redo log 是物理日志，undo log 是逻辑日志）。binlog 记录的都是事务操作内容
binlog 有三种模式：
Statement（基于 SQL 语句的复制）、Row（基于行的复制） 以及 Mixed（混合模式）。
不管采用的是什么模式，当然格式是二进制的，

- 记录时机不同。redo/undo 在 **事务执行过程中** 会不断的写入，而 binlog 是在 **事务最终提交前** 写入的。
binlog 什么时候刷新到磁盘跟参数 `sync_binlog` 相关。
~~~

|          | redo log                                                     | binlog                                                       |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 文件大小 | `redo log `的大小是固定的。                                  | `binlog `可通过配置参数 `max_binlog_size `设置每个` binlog `文件的大小。 |
| 实现方式 | `redo log `是 `InnoDB `引擎层实现的，并不是所有引擎都有。    | `binlog `是 `Server` 层实现的，所有引擎都可以使用 `binlog `日志 |
| 记录方式 | redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。 | binlog通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上 |
| 适用场景 | `redo log `适用于崩溃恢复(crash-safe)                        | `binlog `适用于主从复制和数据恢复                            |
| 记录内容 | 物理日志，记录的是“在某个数据页上做了什么修改”               | 逻辑日志，记录的是这个语句的原始逻辑                         |

##### update 语句时的内部流程：

　　1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。

　　2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。

　　3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。

　　4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。

　　5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。

最后三步，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是"两阶段提交"。























不错：

https://cloud.tencent.com/developer/article/1444390